---
title: "hw6"
author: "Yue Chen"
date: "11/29/2020"
output: github_document
---

```{r setup, include = FALSE}
library(tidyverse)
library(viridis)
library(modelr)
library(mgcv)
library(purrr)

set.seed(1)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

## Problem 1

Import and clean dataset.

```{r}
homicide_df = 
  read_csv("data/homicide-data.csv", na = c("", "NA", "Unknown")) %>%
  mutate(
    city_state = str_c(city, state, sep = ", "), 
    victim_age = as.numeric(victim_age), 
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0, 
      disposition == "Closed by arrest"      ~ 1
    )
  ) %>%
  filter(
    victim_race %in% c("White", "Black"), 
    city_state != "Tulsa, AL"
  ) %>%
  select(city_state, resolution, victim_age, victim_race, victim_sex)
```

Analyze Baltimore, MD.

```{r}
baltimore_df = 
  homicide_df %>%
  filter(city_state == "Baltimore, MD")

glm(resolution ~ victim_age + victim_race + victim_sex, 
    data = baltimore_df,
    family = binomial()) %>%
  broom::tidy() %>%
  mutate(
    OR = exp(estimate), 
    CI_lower = exp(estimate - 1.96 * std.error), 
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>%
  select(term, OR, starts_with("CI")) %>%
  knitr::kable(digits = 3)
```

Analyze each of the cities in the dataset. 

```{r}
models_results_df = 
  homicide_df %>%
  nest(data = -city_state) %>%
  mutate(
    models = 
      map(.x = data, ~glm(resolution ~ victim_age + victim_race + victim_sex, data = .x, family = binomial())), results = map(models, broom::tidy)
  ) %>%
  select(city_state, results) %>%
  unnest(results) %>%
  mutate(
    OR = exp(estimate), 
    CI_lower = exp(estimate - 1.96 * std.error), 
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>%
  select(city_state, term, OR, starts_with("CI"))
```

Create a plot that shows the estimated ORs and CIs for each city.

```{r}
models_results_df %>%
  filter(term == "victim_sexMale") %>%
  mutate(city_state = fct_reorder(city_state, OR)) %>%
  ggplot(aes(x = city_state, y = OR)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

## Problem 2

```{r}
baby_df = 
  read_csv("data/birthweight.csv", na = c("", "NA", "Unknown")) %>%
  mutate(
    babysex = factor(babysex, levels = c(1, 2), labels = c("male", "female")),
    frace = factor(frace, levels = c(1, 2, 3, 4, 8, 9), labels = c("White", "Black", "Asian", "Puerto Rican", "Other", "Unknown")), 
    mrace = factor(mrace, levels = c(1, 2, 3, 4, 8), labels = c("White", "Black", "Asian", "Puerto Rican", "Other")), 
    malform = factor(malform, levels = c(0, 1), labels = c("absent", "present"))
  )
```

Propose a regression model for birthweight.

```{r}
all_model = lm(bwt ~ ., data = baby_df)

step(all_model, direction = "backward")

optimal_model = lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + 
    mheight + mrace + parity + ppwt + smoken, data = baby_df)
```

I ran the forward model selection precedure and the model with the smallest AIC was chosen here. The predictors are baby's sex, baby's head circumferences at birth, baby's length at birth, mother's weight at delivery, family monthly income, gestational age, mother's height, mother's race, number of live births prior to this pregnancy, mother's pre-pregnancy weight, average number of cigarettes smoked per day during pregnancy.

Show a plot of model residuals against fitted values.

```{r}
baby_df %>%
  add_predictions(optimal_model) %>%
  add_residuals(optimal_model) %>%
  ggplot(aes(x = pred, y = resid)) + 
  geom_point(alpha = .2, color = "blue") +
  geom_smooth(aes(y = resid), color = "black", method = "lm") + 
  labs(
    x = "prediction", 
    y = "residual", 
    title = "plot of model residuals vs. fitted values"
  )
```

Residuals approximate to 0 with constant variances.

Compare to other models by cross validation.

```{r}
model1 = lm(bwt ~ blength + gaweeks, data = baby_df)

model2 = lm(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex, data = baby_df)

cv_df = 
  crossv_mc(baby_df, 100) %>%
  mutate(
    train = map(train, as_tibble), 
    test = map(test, as_tibble), 
    optimal_model = map(train, ~lm(bwt ~ babysex + bhead + blength + delwt + fincome + gaweeks + 
    mheight + mrace + parity + ppwt + smoken, data = .x)), 
    model1 = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)), 
    model2 = map(train, ~gam(bwt ~ bhead + blength + babysex + bhead * blength + bhead * babysex + blength * babysex, data = as_tibble(.x)))
  ) %>%
  mutate(
    rmse_optimal_model = map2_dbl(optimal_model, test, ~rmse(model = .x, data = .y)), 
    rmse_model1 = map2_dbl(model1, test, ~rmse(model = .x, data = .y)), 
    rmse_model2 = map2_dbl(model2, test, ~rmse(model = .x, data = .y))
  )
  
cv_df %>%
  select(starts_with("rmse")) %>%
  pivot_longer(
    everything(), 
    names_to = "model", 
    values_to = "rmse", 
    names_prefix = "rmse_"
  ) %>%
  mutate(model = fct_inorder(model)) %>%
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin()
```
According to the violin plot, the optimal model performs the best compared to the other two models since it has the lowest root-mean-square deviation.

## Problem 3

Import dataset.

```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"), 
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01", 
    date_max = "2017-12-31"
  ) %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"), 
    tmin = tmin / 10, 
    tmax = tmax / 10
  ) %>%
  select(name, id, everything())
```
```{r}
boot_strap_results = 
  weather_df %>%
  bootstrap(n = 5000) %>%
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)), 
    tidy_models = map(models, broom::tidy), 
    glance_models = map(models, broom::glance)
  ) %>%
  unnest(tidy_models, glance_models) %>%
  select(.id, term, estimate, r.squared) %>%
  pivot_wider(
    names_from = term, 
    values_from = estimate
  ) %>%
  rename(
    beta0_hat = `(Intercept)`, 
    beta1_hat = tmin
  ) %>%
  mutate(
    log_b0xb1 = log(beta0_hat * beta1_hat)
  ) %>%
  janitor::clean_names() %>%
  select(r_squared, log_b0xb1)
```

Density plot.

```{r}
boot_strap_results %>%
  ggplot(aes(x = r_squared)) + 
  geom_density(fill = "blue") + 
  labs(
    x = ~hat(r)^2, 
    y = "density", 
    title = "distribution of" ~hat(r)^2
  )
```

95% confidence interval. 

```{r}
CI_rsquared = round(quantile(pull(boot_strap_results, r_squared), probs = c(0.025, 0.975)), digits = 2)
```

The r squared is approximately normally distributed. The mean r squared is 0.91. We are 95% confident that the r squared will fall between 0.89 and 0.93. 

Density plot. 

```{r}
boot_strap_results %>%
  ggplot(aes(x = log_b0xb1)) + 
  geom_density(fill = "blue") + 
  labs(
    x = ~log(hat(beta)[0] %*% hat(beta)[1]), 
    y = "Density", 
    title = "distribution of" ~log(hat(beta)[0] %*% hat(beta)[1])
  )
```

95% confidence interval. 

```{r}
CI_log_b0xb1 = round(quantile(pull(boot_strap_results, log_b0xb1), probs = c(0.025, 0.975)), digits = 2)
```

The distribution of `log_b0xb1` is normal and centering at 2.01. We are 95% confident that `log_b0xb1` will fall between 1.96 and 2.06.